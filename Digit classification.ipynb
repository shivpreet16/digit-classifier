{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7e29948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if train_on_gpu:\n",
    "    print(\"Training on GPU\")\n",
    "else:\n",
    "    print(\"Training on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2110a8ce",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "We are using MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1016041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming data into torch tensors\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "#download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle= True)\n",
    "\n",
    "#download and load the Test data\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00a3e73",
   "metadata": {},
   "source": [
    "## Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d65ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fffefedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = nn.LogSoftmax(dim=1)(x)\n",
    "        return x\n",
    "\n",
    "net = Network()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15400b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loss function\n",
    "criterion = nn.NLLLoss()\n",
    "net.to(torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df87d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer\n",
    "from torch import optim\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d64007",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7790a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/15.. training loss: 2.146.. Test Loss: 1.745.. Test Accuracy: 0.660..\n",
      "epoch: 2/15.. training loss: 1.059.. Test Loss: 0.658.. Test Accuracy: 0.828..\n",
      "epoch: 3/15.. training loss: 0.545.. Test Loss: 0.469.. Test Accuracy: 0.871..\n",
      "epoch: 4/15.. training loss: 0.430.. Test Loss: 0.399.. Test Accuracy: 0.889..\n",
      "epoch: 5/15.. training loss: 0.380.. Test Loss: 0.361.. Test Accuracy: 0.899..\n",
      "epoch: 6/15.. training loss: 0.350.. Test Loss: 0.338.. Test Accuracy: 0.904..\n",
      "epoch: 7/15.. training loss: 0.330.. Test Loss: 0.319.. Test Accuracy: 0.909..\n",
      "epoch: 8/15.. training loss: 0.314.. Test Loss: 0.306.. Test Accuracy: 0.913..\n",
      "epoch: 9/15.. training loss: 0.301.. Test Loss: 0.294.. Test Accuracy: 0.915..\n",
      "epoch: 10/15.. training loss: 0.289.. Test Loss: 0.282.. Test Accuracy: 0.919..\n",
      "epoch: 11/15.. training loss: 0.279.. Test Loss: 0.274.. Test Accuracy: 0.922..\n",
      "epoch: 12/15.. training loss: 0.270.. Test Loss: 0.263.. Test Accuracy: 0.925..\n",
      "epoch: 13/15.. training loss: 0.262.. Test Loss: 0.256.. Test Accuracy: 0.927..\n",
      "epoch: 14/15.. training loss: 0.253.. Test Loss: 0.248.. Test Accuracy: 0.929..\n",
      "epoch: 15/15.. training loss: 0.245.. Test Loss: 0.240.. Test Accuracy: 0.932..\n"
     ]
    }
   ],
   "source": [
    "epochs = 15 #number of time the model trains\n",
    "steps = 0\n",
    "\n",
    "train_losses, test_losses = [],[]\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    \n",
    "    net.train()\n",
    "    \n",
    "    for images, labels in trainloader:\n",
    "        #flatten Image\n",
    "        images = images.view(images.shape[0], -1)\n",
    "\n",
    "        #clear gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #forward pass\n",
    "        log_ps = net(images)\n",
    "\n",
    "        #loss and weights\n",
    "        loss = criterion(log_ps, labels)\n",
    "\n",
    "        #calc gredients\n",
    "        loss.backward()\n",
    "\n",
    "        #update weights\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "\n",
    "        #Turn off gradients for validation, saves memory and computations\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                images = images.view(images.shape[0], -1)\n",
    "\n",
    "                log_ps = net(images)\n",
    "                test_loss += criterion(log_ps, labels) \n",
    "\n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "        \n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        test_losses.append(test_loss/len(testloader))\n",
    "\n",
    "        print(\"epoch: {}/{}..\".format(e+1, epochs),\n",
    "              \"training loss: {:.3f}..\".format(running_loss/len(trainloader)),\n",
    "              \"Test Loss: {:.3f}..\".format(test_loss/len(testloader)),\n",
    "              \"Test Accuracy: {:.3f}..\".format(accuracy/len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59029ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted number is:3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx =0\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "img = images[idx].view(1,784)\n",
    "\n",
    "ps = torch.exp(net(img))\n",
    "print(f'predicted number is:{int(torch.argmax(ps))}')\n",
    "plt.imshow(images[idx].view(28,28))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773cafc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a90aeebcf29d64a654773811cc170cb25061cb2498f10ac689db374c7bf325de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
